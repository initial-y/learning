# 并发容器

## 简述

- ConcurrentHashMap：线程安全的HashMap；
- CopyOnWriteArrayList：线程安全的List，在**读多写少**的场合性能非常好；
- ConcurrentLinkedQueue：高效的并发队列，使用链表实现。可以看做线程安全的LinkedList，是一个非阻塞队列。
- BlockingQueue：接口，JDK内部使用链表、数组等方式实现这个接口。表示阻塞队列，适合于作为数据共享的通道。
- ConcurrentSkipListMap：跳表。

## ConcurrentHashMap

HashMap的线程安全版本。

在ConcurrentHashMap中，读写操作都能保证很高的性能：在进行读操作时（几乎）不需要加锁，在写操作时通过锁分段计数只对所操作的段加锁，不影响对其他段的访问。

### 源码

```java
public class ConcurrentHashMap<K,V> extends AbstractMap<K,V>
implements ConcurrentMap<K,V>, Serializable {
/**
     * The largest possible table capacity.  This value must be
     * exactly 1<<30 to stay within Java array allocation and indexing
     * bounds for power of two table sizes, and is further required
     * because the top two bits of 32bit hash fields are used for
     * control purposes.
     */
    private static final int MAXIMUM_CAPACITY = 1 << 30;

    /**
     * The default initial table capacity.  Must be a power of 2
     * (i.e., at least 1) and at most MAXIMUM_CAPACITY.
     */
    private static final int DEFAULT_CAPACITY = 16;

    /**
     * The largest possible (non-power of two) array size.
     * Needed by toArray and related methods.
     */
    static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;

    /**
     * The default concurrency level for this table. Unused but
     * defined for compatibility with previous versions of this class.
     */
    private static final int DEFAULT_CONCURRENCY_LEVEL = 16;

    /**
     * The load factor for this table. Overrides of this value in
     * constructors affect only the initial table capacity.  The
     * actual floating point value isn't normally used -- it is
     * simpler to use expressions such as {@code n - (n >>> 2)} for
     * the associated resizing threshold.
     */
    private static final float LOAD_FACTOR = 0.75f;

    /**
     * The bin count threshold for using a tree rather than list for a
     * bin.  Bins are converted to trees when adding an element to a
     * bin with at least this many nodes. The value must be greater
     * than 2, and should be at least 8 to mesh with assumptions in
     * tree removal about conversion back to plain bins upon
     * shrinkage.
     */
    static final int TREEIFY_THRESHOLD = 8;

    /**
     * The bin count threshold for untreeifying a (split) bin during a
     * resize operation. Should be less than TREEIFY_THRESHOLD, and at
     * most 6 to mesh with shrinkage detection under removal.
     */
    static final int UNTREEIFY_THRESHOLD = 6;

    /**
     * The smallest table capacity for which bins may be treeified.
     * (Otherwise the table is resized if too many nodes in a bin.)
     * The value should be at least 4 * TREEIFY_THRESHOLD to avoid
     * conflicts between resizing and treeification thresholds.
     */
    static final int MIN_TREEIFY_CAPACITY = 64;

    /**
     * Minimum number of rebinnings per transfer step. Ranges are
     * subdivided to allow multiple resizer threads.  This value
     * serves as a lower bound to avoid resizers encountering
     * excessive memory contention.  The value should be at least
     * DEFAULT_CAPACITY.
     */
    private static final int MIN_TRANSFER_STRIDE = 16;

    /**
     * The number of bits used for generation stamp in sizeCtl.
     * Must be at least 6 for 32bit arrays.
     */
    private static int RESIZE_STAMP_BITS = 16;

    /**
     * The maximum number of threads that can help resize.
     * Must fit in 32 - RESIZE_STAMP_BITS bits.
     */
    private static final int MAX_RESIZERS = (1 << (32 - RESIZE_STAMP_BITS)) - 1;

    /**
     * The bit shift for recording size stamp in sizeCtl.
     */
    private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;

    /*
     * Encodings for Node hash fields. See above for explanation.
     */
    static final int MOVED     = -1; // hash for forwarding nodes
    static final int TREEBIN   = -2; // hash for roots of trees
    static final int RESERVED  = -3; // hash for transient reservations
    static final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash

    /** Number of CPUS, to place bounds on some sizings */
    static final int NCPU = Runtime.getRuntime().availableProcessors();

    /** For serialization compatibility. */
    private static final ObjectStreamField[] serialPersistentFields = {
        new ObjectStreamField("segments", Segment[].class),
        new ObjectStreamField("segmentMask", Integer.TYPE),
        new ObjectStreamField("segmentShift", Integer.TYPE)
    };
}
```

#### put()/putVal()

```java
    /**
     * 将指定的键映射到指定的值。键和值都不能为null。
     * Maps the specified key to the specified value in this table.
     * Neither the key nor the value can be null.
     *
     * <p>The value can be retrieved by calling the {@code get} method
     * with a key that is equal to the original key.
     *
     * @param key key with which the specified value is to be associated
     * @param value value to be associated with the specified key
     * @return the previous value associated with {@code key}, or
     *         {@code null} if there was no mapping for {@code key}
     * @throws NullPointerException if the specified key or value is null
     */
    public V put(K key, V value) {
        return putVal(key, value, false);
    }

    /** Implementation for put and putIfAbsent */
    final V putVal(K key, V value, boolean onlyIfAbsent) {
        // 键和值都不能为null
        if (key == null || value == null) throw new NullPointerException();
        // 根据key异或获取hash值
        int hash = spread(key.hashCode());
        int binCount = 0;
        // 自旋
        for (Node<K,V>[] tab = table;;) {
            Node<K,V> f; int n, i, fh;
            // 判断是否需要初始化,疑问?初始化的什么,为什么要初始化
            if (tab == null || (n = tab.length) == 0)
                // CAS初始化, 注意这里初始化 并没有 跳出循环
                tab = initTable();
            // f 即为当前 key 定位出的 Node，如果为null表示当前位置的bucket是空的,可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。
            // tabAt():根据key定位位置
            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
                // casTabAt():插入数据???
                if (casTabAt(tab, i, null,
                             new Node<K,V>(hash, key, value, null)))
                    // 插入成功跳出循环
                    break;                   // no lock when adding to empty bin
            }
            // 走到这里,表明定位位置不为空(之前这里有数据)
            // hash值=MOVED = -1, hash值不正常,
            else if ((fh = f.hash) == MOVED)
                // todo, 没看
                tab = helpTransfer(tab, f);
            // 走到这里,表示hash值正常, 使用sychronized锁住当前节点
            else {
                V oldVal = null;
                // 注意，多线程请求不同的hash桶时（不同的key），支持并发操作，同一个key会被锁住
                synchronized (f) {
                    if (tabAt(tab, i) == f) {
                        // 此时fh是当前节点的hash值
                        if (fh >= 0) {
                            binCount = 1;
                            // fh>0,链式遍历, f是当前节点
                            for (Node<K,V> e = f;; ++binCount) {
                                K ek;
                                // 如果遍历到key匹配,覆盖
                                if (e.hash == hash &&
                                    ((ek = e.key) == key ||
                                     (ek != null && key.equals(ek)))) {
                                    oldVal = e.val;
                                    // put()这个参数传的false,会进入判断
                                    // todo ? 这个参数控制什么?
                                    if (!onlyIfAbsent)
                                        e.val = value;
                                    // 覆盖后会跳出循环
                                    break;
                                }
                                Node<K,V> pred = e;
                                // 判断是否到末尾
                                if ((e = e.next) == null) {
                                    // 如果遍历到末尾都没有key匹配,则将val插入到链表尾部
                                    pred.next = new Node<K,V>(hash, key,
                                                              value, null);
                                    // 插入到链尾也会跳出循环
                                    break;
                                }
                            }
                        }
                        // 此时fh<0,判断f是否被转换为TreeNode(TreeBin实现红黑树)
                        // todo : 有一点疑问?TREEIFY_THRESHOLD在哪里有用到?
                        else if (f instanceof TreeBin) {
                            // 如果链表长度超过或等于8（TREEIFY_THRESHOLD），结点会被转换成TreeNode（由TreeBin实现红黑树）
                            // todo ?没看明白
                            Node<K,V> p;
                            binCount = 2;
                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                           value)) != null) {
                                oldVal = p.val;
                                if (!onlyIfAbsent)
                                    p.val = value;
                            }
                        }
                    }
                }
                // 此处转化为红黑树
                if (binCount != 0) {
                    if (binCount >= TREEIFY_THRESHOLD)
                        treeifyBin(tab, i);
                    if (oldVal != null)
                        return oldVal;
                    break;
                }
            }
        }
        // 添加计数
        addCount(1L, binCount);
        return null;
    }

    /**
      * 源自翻译：
      *  散布（XOR）较高位的散列值降低并强制顶部位为0.因为该表使用2次幂掩蔽，仅在当前掩码之上的位变化的散列集将始终发生冲突。 
	 * （在已知的例子中是一组Float键，在小表中保存连续的整数。）因此我们应用一个向下传播高位比特影响的变换。
	 * 在速度，效用和比特扩展质量之间存在权衡。
	 * 因为许多常见的哈希集合已经合理分布（因此不会受益于传播），并且因为我们使用树来处理容器中的大量冲突，所以我们只是以最便宜的方式对一些移位的位进行异或，以减少系统损失，
	 * 以及由于表格边界而包含最高位的影响，否则这些位将永远不会用于索引计算。
     * Spreads (XORs) higher bits of hash to lower and also forces top
     * bit to 0. Because the table uses power-of-two masking, sets of
     * hashes that vary only in bits above the current mask will
     * always collide. (Among known examples are sets of Float keys
     * holding consecutive whole numbers in small tables.)  So we
     * apply a transform that spreads the impact of higher bits
     * downward. There is a tradeoff between speed, utility, and
     * quality of bit-spreading. Because many common sets of hashes
     * are already reasonably distributed (so don't benefit from
     * spreading), and because we use trees to handle large sets of
     * collisions in bins, we just XOR some shifted bits in the
     * cheapest possible way to reduce systematic lossage, as well as
     * to incorporate impact of the highest bits that would otherwise
     * never be used in index calculations because of table bounds.
     */
    static final int spread(int h) {
        return (h ^ (h >>> 16)) & HASH_BITS;
    }

    /**
     * Initializes table, using the size recorded in sizeCtl.
     */
    private final Node<K,V>[] initTable() {
        Node<K,V>[] tab; int sc;
        while ((tab = table) == null || tab.length == 0) {
            if ((sc = sizeCtl) < 0)
                Thread.yield(); // lost initialization race; just spin
            // 此处使用了CAS，？？？compareAndSwapInt起什么作用？
            else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
                try {
                    // 初始化
                    if ((tab = table) == null || tab.length == 0) {
                        // 指定大小
                        int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                        // 这里看得出底层用的是Node数组
                        @SuppressWarnings("unchecked")
                        Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                        table = tab = nt;
                        // n - n/4 (>>>：无符号右移，忽略符号位)
                        // ？？？这步的作用是？
                        sc = n - (n >>> 2);
                    }
                } finally {
                    // 如果容量为DEFAULT_CAPACITY，这里sizeCtl = DEFAULT_CAPACITY * LOAD_FACTOR,???
                    sizeCtl = sc;
                }
                break;
            }
        }
        return tab;
    }
    /**
     * 初始化和调整大小时使用。
     * 当该值为负数时，表示table正在初始化或者在调整大小：-1表示初始化
     * 初始化之后，会保存下一个元素的计数值，在该值上调整表的大小？？？
     * Table initialization and resizing control.  When negative, the
     * table is being initialized or resized: -1 for initialization,
     * else -(1 + the number of active resizing threads).  Otherwise,
     * when table is null, holds the initial table size to use upon
     * creation, or 0 for default. After initialization, holds the
     * next element count value upon which to resize the table.
     */
    private transient volatile int sizeCtl;

```

put原理示意图：

![put原理](<https://upload-images.jianshu.io/upload_images/6283837-b6d5663539a068c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp>)

锁的粒度是hash桶，多个put线程只有在请求同一个hash桶时，才会被阻塞。请求不同hash桶的put线程，可以并发执行。

put线程，请求的hash桶为空时，采用for循环+CAS的方式无锁插入。

#### get()

```java
	/**	
	 * 返回指定key映射的值, 没有找到映射的值返回null
     * Returns the value to which the specified key is mapped,
     * or {@code null} if this map contains no mapping for the key.
     *
     * <p>More formally, if this map contains a mapping from a key
     * {@code k} to a value {@code v} such that {@code key.equals(k)},
     * then this method returns {@code v}; otherwise it returns
     * {@code null}.  (There can be at most one such mapping.)
     *
     * @throws NullPointerException if the specified key is null
     */
    public V get(Object key) {
        Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
        // 根据key获取hash值(二次hash)
        int h = spread(key.hashCode());
        if ((tab = table) != null && (n = tab.length) > 0 &&
        // 根据hash值定位node的位置, e就是找到的node(此时是bucket)
        // tabAt: 最终通过unsafe类的原子操作，获取数组结点
            (e = tabAt(tab, (n - 1) & h)) != null) {
            // 先判断e的hash值是否等于key的hash值(value值在bucket上)
            if ((eh = e.hash) == h) {
                // 再判断e的key是否等于传入的key, 如果相等, 则返回e.val
                if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                    return e.val;
            }
            // eh = e.hash, e的hash值<0,代表不在bucket上
            else if (eh < 0)
                // 通过find()链式查找匹配的节点p,找到返回p.val,找不到返回null
                return (p = e.find(h, key)) != null ? p.val : null;
            // 注意, 此时e.hash != key的hash 并且 e.hash >= 0
            while ((e = e.next) != null) {
                if (e.hash == h &&
                    ((ek = e.key) == key || (ek != null && key.equals(ek))))
                    return e.val;
            }
        }
        return null;
    }

        /**
         * Virtualized support for map.get(); overridden in subclasses.
         */
        Node<K,V> find(int h, Object k) {
            Node<K,V> e = this;
            // k是传入的key
            if (k != null) {
                // 链式查找直到最后一个节点
                do {
                    K ek;
                    if (e.hash == h &&
                        ((ek = e.key) == k || (ek != null && k.equals(ek))))
                        return e;
                } while ((e = e.next) != null);
            }
            return null;
        }
```



#### size()

```java
/**
 * 获取map大小
 */
public int size() {
    // 获取计数器的值
    long n = sumCount();
    // 返回0到Integer.MAX_VALUE之间的值
    return ((n < 0L) ? 0 :
            (n > (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE :
            (int)n);
}

final long sumCount() {
    // CounterCell：用于分配计数的填充单元格。改编自LongAdder和Striped64。
    // private transient volatile CounterCell[] counterCells; 
    // 计数用，不为空时，大小为2的幂次
    CounterCell[] as = counterCells; CounterCell a;
    // private transient volatile long baseCount;
    // 基本计数器值，主要在没有竞争时使用；也作为在表初始化时的备用？？。这个值	通过CAS更新。
    long sum = baseCount;
    // as不为空，计数值通过as计算；as为空，返回基本计数值。
    if (as != null) {
        for (int i = 0; i < as.length; ++i) {
            if ((a = as[i]) != null)
                sum += a.value;
        }
    }
    return sum;
}

@sun.misc.Contended static final class CounterCell {
    volatile long value;
    CounterCell(long x) { value = x; }
}
```

resizeStamp

```java
 /**
     * Returns the stamp bits for resizing a table of size n.
     * Must be negative when shifted left by RESIZE_STAMP_SHIFT.
     */
    static final int resizeStamp(int n) {
        return Integer.numberOfLeadingZeros(n) | (1 << (RESIZE_STAMP_BITS - 1));
    }
```

#### remove()

```java
    /**
     * 从map里移除key， 如果key不在map里， 该方法不执行任何操作
     * Removes the key (and its corresponding value) from this map.
     * This method does nothing if the key is not in the map.
     *
     * @param  key the key that needs to be removed
     * 返回key之前匹配的值， 如果没有匹配的key返回null
     * @return the previous value associated with {@code key}, or
     *         {@code null} if there was no mapping for {@code key}
     * @throws NullPointerException if the specified key is null
     */
    public V remove(Object key) {
        return replaceNode(key, null, null);
    }

    /**
     * The array of bins. Lazily initialized upon first insertion.
     * Size is always a power of two. Accessed directly by iterators.
     */
    transient volatile Node<K,V>[] table;

    /**
     * 四种公共的remove/replace方法的实现。
     * 用v替换节点值，如果cv不为空，使用cv替换。
     * Implementation for the four public remove/replace methods:
     * Replaces node value with v, conditional upon match of cv if
     * non-null.  If resulting value is null, delete.
     */
	// 为什么要cv和value两个值
    final V replaceNode(Object key, V value, Object cv) {
        // key的hash值
        int hash = spread(key.hashCode());
        // 自旋
        for (Node<K,V>[] tab = table;;) {
            Node<K,V> f; int n, i, fh;
          	// 如果tab为null（map没有初始化） || tab初始化了但是找不到数组节点值， 跳出循环，返回null
            if (tab == null || (n = tab.length) == 0 ||
                (f = tabAt(tab, i = (n - 1) & hash)) == null)
                break;
            // 如果找到数组节点的hash值为负， 扩容？
            else if ((fh = f.hash) == MOVED)
                tab = helpTransfer(tab, f);
            // 找到匹配的数组节点
            else {
                V oldVal = null;
                boolean validated = false;
                // 与putval一样， 锁住当前bucket， 多线程请求不同key支持并发，相同key不行
                synchronized (f) {
                    if (tabAt(tab, i) == f) {
                        if (fh >= 0) {
                            validated = true;
                            // 自旋+1 , pred???
                            for (Node<K,V> e = f, pred = null;;) {
                                K ek;
                                // 再次确认key对应的节点与当前节点是否匹配，确定对应的node
                                if (e.hash == hash &&
                                    ((ek = e.key) == key ||
                                     (ek != null && key.equals(ek)))) {
                                    V ev = e.val;
                                    // cv：期望值
                                    // 如果cv为null:直接更新value/删除节点
                                    // cv不等于null，只在当前节点的值等于期望值cv的时候才做更新/删除操作
                                    if (cv == null || cv == ev ||
                                        (ev != null && cv.equals(ev))) {
                                        oldVal = ev;
                                        // 需要更新的值不等于null， 直接更新
                                        if (value != null)
                                            e.val = value;
                                        // 删除非头结点
                                        else if (pred != null)
                                            pred.next = e.next;
                                        // 删除头结点
                                        else
                                            // 之前已经获取了头结点的锁
                                            setTabAt(tab, i, e.next);
                                    }
                                    break;
                                }
                                // key对应的节点与当前节点不匹配，继续遍历下一个节点
                                pred = e;
                                if ((e = e.next) == null)
                                    break;
                            }
                        }
                        // fh<0, 红黑树的处理 疑问？？这里怎么就fh<0了
                        else if (f instanceof TreeBin) {
                            validated = true;
                            TreeBin<K,V> t = (TreeBin<K,V>)f;
                            TreeNode<K,V> r, p;
                            if ((r = t.root) != null &&
                                (p = r.findTreeNode(hash, key, null)) != null) {
                                V pv = p.val;
                                if (cv == null || cv == pv ||
                                    (pv != null && cv.equals(pv))) {
                                    oldVal = pv;
                                    if (value != null)
                                        p.val = value;
                                    else if (t.removeTreeNode(p))
                                        setTabAt(tab, i, untreeify(t.first));
                                }
                            }
                        }
                    }
                }
                if (validated) {
                    if (oldVal != null) {
                        // 删除节点 更新size大小
                        if (value == null)
                            addCount(-1L, -1);
                        return oldVal;
                    }
                    break;
                }
            }
        }
        return null;
    }
```

remove方法图示：

![remove并发原理](<https://upload-images.jianshu.io/upload_images/6283837-95df888f4f738601.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/916/format/webp>)

由图所示，多线程请求不同的hash值，支持并发。

### 参考

- [HashMap? ConcurrentHashMap? 相信看完这篇没人能难住你！](<https://crossoverjie.top/2018/07/23/java-senior/ConcurrentHashMap/>)
- [ConcurrentHashMap实现分析与使用](<https://zhangzemiao.com/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/ConcurrentHashMap%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90%E4%B8%8E%E4%BD%BF%E7%94%A8/>)



## CopyOnWriteArrayList

主要针对于**读操作远大于写操作**的场景。因为读操作不会修改原有的数据，所以不用对每次读取进行加锁。在进行读操作时，我们应允许多个线程同时访问List的内部数据。

CopyOnWriteArrayList的读取操作时**完全**不用加锁的，同时写入也不会阻塞读取操作，只有在**写入和写入之间**需要进行同步等待。

### 读取操作

全程未加锁，内部array数组不会更改，只会被另一个array替换。

···

### 写入操作

add()在添加集合时加锁，避免多线程操作时拷贝多个副本出来。

···

## ConcurrentLinkedQueue

### 阻塞队列与非阻塞队列

Java中线程安全的Queue分为**阻塞队列**和**非阻塞队列**。

阻塞队列的代表：**BlockingQueue**。

非阻塞队列的代表：**ConcurrentLinkedQueue**。

### ConcurrentLinkedQueue

使用链表作为底层数据结构。底层主要使用**CAS非阻塞算法**来实现线程安全。

ConcurrentLinkedQueue适用于对性能要求相对较高，同时存在多线程队列读写同时进行的场景。

## BlockingQueue

阻塞队列BlockingQueue广泛应用于**生产者-消费者**问题中，原因是BlockingQueue提供了可阻塞的插入和移除方法。当队列容器已满，生产者线程会被阻塞，知道队列处于未满状态；当队列为空时，消费者线程会被阻塞，知道队列为非空。

BlockingQueue是一个继承自Queue的接口。实现类可以作为Queue的实现来使用。

### ArrayBlockingQueue

BlockingQueue的有界队列实现类，底层采用**数组**实现。

### LinkedBlockingQueue

基于**单向链表**实现的阻塞队列，即可当做**无界队列**也可以当做**有界队列**来使用。

### PriorityBlockingQueue

支持优先级的无界阻塞队列。

## ConcurrentSkipListMap

### 跳表

跳表是一种空间换时间的算法。